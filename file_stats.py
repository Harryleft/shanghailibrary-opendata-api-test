#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶ç»Ÿè®¡è„šæœ¬
ç»Ÿè®¡ api_results ç›®å½•ä¸‹çš„æ–‡ä»¶æ•°é‡ã€å¤§å°ç­‰ä¿¡æ¯
"""

import os
import json
from pathlib import Path
from collections import defaultdict


def analyze_api_results():
    """åˆ†æ api_results ç›®å½•ä¸‹çš„æ–‡ä»¶"""
    api_results_path = Path("api_results")

    if not api_results_path.exists():
        print("âŒ api_results ç›®å½•ä¸å­˜åœ¨")
        return

    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        "total_files": 0,
        "total_size": 0,
        "file_types": defaultdict(int),
        "file_type_sizes": defaultdict(int),
        "categories": defaultdict(int),
        "largest_files": [],
        "files_by_category": defaultdict(list)
    }

    print("ğŸ” æ­£åœ¨åˆ†æ api_results ç›®å½•...")
    print("=" * 60)

    # éå†æ‰€æœ‰æ–‡ä»¶
    for file_path in api_results_path.rglob("*"):
        if file_path.is_file():
            # åŸºæœ¬ç»Ÿè®¡
            file_size = file_path.stat().st_size
            file_ext = file_path.suffix.lower()
            file_name = file_path.name

            stats["total_files"] += 1
            stats["total_size"] += file_size
            stats["file_types"][file_ext] += 1
            stats["file_type_sizes"][file_ext] += file_size

            # åˆ†ææ–‡ä»¶ç±»åˆ«ï¼ˆä»æ–‡ä»¶åä¸­æå–ï¼‰
            if file_name.startswith("[") and "]" in file_name:
                category = file_name.split("]")[0][1:]
                stats["categories"][category] += 1
                stats["files_by_category"][category].append(file_name)

            # è®°å½•æœ€å¤§çš„æ–‡ä»¶
            stats["largest_files"].append((file_name, file_size))

    # æ’åºæœ€å¤§æ–‡ä»¶
    stats["largest_files"].sort(key=lambda x: x[1], reverse=True)
    stats["largest_files"] = stats["largest_files"][:10]  # åªä¿ç•™å‰10ä¸ª

    return stats


def format_size(size_bytes):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size_bytes < 1024.0:
            return f"{size_bytes:.2f} {unit}"
        size_bytes /= 1024.0
    return f"{size_bytes:.2f} TB"


def print_stats(stats):
    """æ‰“å°ç»Ÿè®¡ç»“æœ"""
    print(f"ğŸ“Š æ–‡ä»¶ç»Ÿè®¡ç»“æœ")
    print("=" * 60)
    print(f"ğŸ“ æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
    print(f"ğŸ’¾ æ€»å¤§å°: {format_size(stats['total_size'])}")
    print()

    # æ–‡ä»¶ç±»å‹ç»Ÿè®¡
    print("ğŸ“‹ æ–‡ä»¶ç±»å‹åˆ†å¸ƒ:")
    for ext, count in sorted(stats["file_types"].items(), key=lambda x: x[1], reverse=True):
        size = format_size(stats["file_type_sizes"][ext])
        ext_display = ext if ext else "(æ— æ‰©å±•å)"
        print(f"  {ext_display:<10} {count:>3} ä¸ªæ–‡ä»¶  {size:>10}")
    print()

    # åˆ†ç±»ç»Ÿè®¡
    print("ğŸ·ï¸  API åˆ†ç±»ç»Ÿè®¡:")
    for category, count in sorted(stats["categories"].items(), key=lambda x: x[1], reverse=True):
        print(f"  {category:<15} {count:>3} ä¸ªæ–‡ä»¶")
    print()

    # æœ€å¤§æ–‡ä»¶
    print("ğŸ“ˆ æœ€å¤§çš„æ–‡ä»¶ (å‰10ä¸ª):")
    for i, (filename, size) in enumerate(stats["largest_files"], 1):
        print(f"  {i:>2}. {filename:<50} {format_size(size):>10}")
    print()

    # è¯¦ç»†åˆ†ç±»ä¿¡æ¯
    print("ğŸ“ è¯¦ç»†åˆ†ç±»æ–‡ä»¶åˆ—è¡¨:")
    for category, files in sorted(stats["files_by_category"].items()):
        print(f"\n  [{category}] ({len(files)} ä¸ªæ–‡ä»¶):")
        for file in sorted(files):
            print(f"    - {file}")


def save_stats_to_json(stats):
    """å°†ç»Ÿè®¡ç»“æœä¿å­˜ä¸ºJSONæ–‡ä»¶"""
    # è½¬æ¢ defaultdict ä¸ºæ™®é€š dict
    json_stats = {
        "total_files": stats["total_files"],
        "total_size": stats["total_size"],
        "total_size_formatted": format_size(stats["total_size"]),
        "file_types": dict(stats["file_types"]),
        "file_type_sizes": {k: {"count": stats["file_types"][k],
                               "size": v,
                               "size_formatted": format_size(v)}
                           for k, v in stats["file_type_sizes"].items()},
        "categories": dict(stats["categories"]),
        "largest_files": [{"name": name, "size": size, "size_formatted": format_size(size)}
                         for name, size in stats["largest_files"]],
        "files_by_category": {k: list(v) for k, v in stats["files_by_category"].items()}
    }

    output_file = "api_results_stats.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(json_stats, f, ensure_ascii=False, indent=2)

    print(f"ğŸ’¾ ç»Ÿè®¡ç»“æœå·²ä¿å­˜åˆ°: {output_file}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ä¸Šæµ·å›¾ä¹¦é¦†å¼€æ”¾æ•°æ® API æµ‹è¯•é¡¹ç›®æ–‡ä»¶ç»Ÿè®¡")
    print("=" * 60)

    stats = analyze_api_results()
    if stats:
        print_stats(stats)
        save_stats_to_json(stats)

        # ç»™å‡ºä¼˜åŒ–å»ºè®®
        print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        if stats["total_size"] > 10 * 1024 * 1024:  # å¤§äº10MB
            print("  - è€ƒè™‘å°†å¤§æ–‡ä»¶æ·»åŠ åˆ° .gitignore ä¸­")
        if ".pdf" in stats["file_types"]:
            print("  - PDF æ–‡ä»¶é€šå¸¸è¾ƒå¤§ï¼Œå»ºè®®ä¸æäº¤åˆ° git ä»“åº“")
        if stats["total_files"] > 100:
            print("  - æ–‡ä»¶æ•°é‡è¾ƒå¤šï¼Œè€ƒè™‘åˆ†ç±»æ•´ç†æˆ–å‹ç¼©")


if __name__ == "__main__":
    main()
